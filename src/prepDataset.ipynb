{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepration of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datafiles\n",
    "- First, load the data files from `../dataset/train-dataset/` folder.\n",
    "- Then select the necessary columns and convert them to pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__header__', '__version__', '__globals__', 'X097_DE_time', 'X097_FE_time', 'X097RPM']\n",
      "['__header__', '__version__', '__globals__', 'X105_DE_time', 'X105_FE_time', 'X105_BA_time', 'X105RPM']\n",
      "['__header__', '__version__', '__globals__', 'X118_DE_time', 'X118_FE_time', 'X118_BA_time', 'X118RPM']\n",
      "['__header__', '__version__', '__globals__', 'X130_DE_time', 'X130_FE_time', 'X130_BA_time', 'X130RPM']\n",
      "['__header__', '__version__', '__globals__', 'X169_DE_time', 'X169_FE_time', 'X169_BA_time', 'X169RPM']\n",
      "['__header__', '__version__', '__globals__', 'X185_DE_time', 'X185_FE_time', 'X185_BA_time', 'X185RPM']\n",
      "['__header__', '__version__', '__globals__', 'X197_DE_time', 'X197_FE_time', 'X197_BA_time', 'X197RPM']\n",
      "['__header__', '__version__', '__globals__', 'X209_DE_time', 'X209_FE_time', 'X209_BA_time', 'X209RPM']\n",
      "['__header__', '__version__', '__globals__', 'X222_DE_time', 'X222_FE_time', 'X222_BA_time', 'X222RPM']\n",
      "['__header__', '__version__', '__globals__', 'X234_DE_time', 'X234_FE_time', 'X234_BA_time', 'X234RPM']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../dataset/train-dataset/\" # Define the path to the training set\n",
    "file_paths = []\n",
    "\n",
    "for file in os.listdir(dataset_path):\n",
    "    # Process each file in the dataset\n",
    "    file_path = os.path.join(dataset_path, file)\n",
    "    data = scipy.io.loadmat(f'{file_path}')\n",
    "    file_paths.append(file_path)\n",
    "    \n",
    "    print(list(data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_columns = ['X097_DE_time', 'X105_DE_time', 'X118_DE_time', 'X130_DE_time', 'X169_DE_time',\n",
    "                'X185_DE_time', 'X197_DE_time', 'X209_DE_time', 'X222_DE_time', 'X234_DE_time']\n",
    "                \n",
    "columns_name = ['de_normal','de_7_inner','de_7_ball','de_7_outer','de_14_inner','de_14_ball','de_14_outer','de_21_inner','de_21_ball','de_21_outer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_path = 'files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de_7_inner</th>\n",
       "      <th>de_7_ball</th>\n",
       "      <th>de_7_outer</th>\n",
       "      <th>de_14_inner</th>\n",
       "      <th>de_14_ball</th>\n",
       "      <th>de_14_outer</th>\n",
       "      <th>de_21_inner</th>\n",
       "      <th>de_21_ball</th>\n",
       "      <th>de_21_outer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de_normal</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.053197</th>\n",
       "      <td>-0.083004</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>-0.223836</td>\n",
       "      <td>-0.467813</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>1.189431</td>\n",
       "      <td>-0.007959</td>\n",
       "      <td>0.104365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.088662</th>\n",
       "      <td>-0.195734</td>\n",
       "      <td>-0.096324</td>\n",
       "      <td>0.423550</td>\n",
       "      <td>-0.209541</td>\n",
       "      <td>0.179004</td>\n",
       "      <td>-0.104948</td>\n",
       "      <td>-0.177866</td>\n",
       "      <td>0.025340</td>\n",
       "      <td>0.017462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.099718</th>\n",
       "      <td>0.233419</td>\n",
       "      <td>0.113705</td>\n",
       "      <td>0.012995</td>\n",
       "      <td>0.345337</td>\n",
       "      <td>0.481295</td>\n",
       "      <td>0.082010</td>\n",
       "      <td>-0.774816</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.116547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.058621</th>\n",
       "      <td>0.103958</td>\n",
       "      <td>0.257297</td>\n",
       "      <td>-0.265175</td>\n",
       "      <td>0.158862</td>\n",
       "      <td>-0.158212</td>\n",
       "      <td>0.094027</td>\n",
       "      <td>0.501518</td>\n",
       "      <td>0.092913</td>\n",
       "      <td>0.371164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.004590</th>\n",
       "      <td>-0.181115</td>\n",
       "      <td>-0.058314</td>\n",
       "      <td>0.237155</td>\n",
       "      <td>-0.206617</td>\n",
       "      <td>-0.326819</td>\n",
       "      <td>-0.160081</td>\n",
       "      <td>0.993697</td>\n",
       "      <td>-0.007797</td>\n",
       "      <td>0.356951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.002712</th>\n",
       "      <td>0.046781</td>\n",
       "      <td>-0.239592</td>\n",
       "      <td>-0.122232</td>\n",
       "      <td>0.046781</td>\n",
       "      <td>-0.002274</td>\n",
       "      <td>-0.056920</td>\n",
       "      <td>-0.296850</td>\n",
       "      <td>0.018842</td>\n",
       "      <td>-0.024365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.016689</th>\n",
       "      <td>-0.071309</td>\n",
       "      <td>0.013482</td>\n",
       "      <td>-1.248720</td>\n",
       "      <td>-0.090314</td>\n",
       "      <td>-0.042883</td>\n",
       "      <td>0.048475</td>\n",
       "      <td>0.060913</td>\n",
       "      <td>-0.075370</td>\n",
       "      <td>-0.044264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.008762</th>\n",
       "      <td>-0.175917</td>\n",
       "      <td>0.217663</td>\n",
       "      <td>0.587609</td>\n",
       "      <td>0.026639</td>\n",
       "      <td>-0.027289</td>\n",
       "      <td>0.107100</td>\n",
       "      <td>0.148628</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.042639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.034004</th>\n",
       "      <td>-0.290759</td>\n",
       "      <td>-0.016081</td>\n",
       "      <td>0.352890</td>\n",
       "      <td>0.097136</td>\n",
       "      <td>-0.035736</td>\n",
       "      <td>-0.033332</td>\n",
       "      <td>-0.139288</td>\n",
       "      <td>0.152364</td>\n",
       "      <td>-0.059289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-0.103890</th>\n",
       "      <td>-0.425418</td>\n",
       "      <td>-0.136283</td>\n",
       "      <td>-0.569741</td>\n",
       "      <td>-0.033624</td>\n",
       "      <td>-0.043208</td>\n",
       "      <td>-0.038772</td>\n",
       "      <td>-0.160811</td>\n",
       "      <td>0.055715</td>\n",
       "      <td>-0.127512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119808 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           de_7_inner  de_7_ball  de_7_outer  de_14_inner  de_14_ball  \\\n",
       "de_normal                                                               \n",
       " 0.053197   -0.083004  -0.002761    0.008528    -0.223836   -0.467813   \n",
       " 0.088662   -0.195734  -0.096324    0.423550    -0.209541    0.179004   \n",
       " 0.099718    0.233419   0.113705    0.012995     0.345337    0.481295   \n",
       " 0.058621    0.103958   0.257297   -0.265175     0.158862   -0.158212   \n",
       "-0.004590   -0.181115  -0.058314    0.237155    -0.206617   -0.326819   \n",
       "...               ...        ...         ...          ...         ...   \n",
       " 0.002712    0.046781  -0.239592   -0.122232     0.046781   -0.002274   \n",
       " 0.016689   -0.071309   0.013482   -1.248720    -0.090314   -0.042883   \n",
       " 0.008762   -0.175917   0.217663    0.587609     0.026639   -0.027289   \n",
       "-0.034004   -0.290759  -0.016081    0.352890     0.097136   -0.035736   \n",
       "-0.103890   -0.425418  -0.136283   -0.569741    -0.033624   -0.043208   \n",
       "\n",
       "           de_14_outer  de_21_inner  de_21_ball  de_21_outer  \n",
       "de_normal                                                     \n",
       " 0.053197     0.002274     1.189431   -0.007959     0.104365  \n",
       " 0.088662    -0.104948    -0.177866    0.025340     0.017462  \n",
       " 0.099718     0.082010    -0.774816    0.000162     0.116547  \n",
       " 0.058621     0.094027     0.501518    0.092913     0.371164  \n",
       "-0.004590    -0.160081     0.993697   -0.007797     0.356951  \n",
       "...                ...          ...         ...          ...  \n",
       " 0.002712    -0.056920    -0.296850    0.018842    -0.024365  \n",
       " 0.016689     0.048475     0.060913   -0.075370    -0.044264  \n",
       " 0.008762     0.107100     0.148628    0.032162     0.042639  \n",
       "-0.034004    -0.033332    -0.139288    0.152364    -0.059289  \n",
       "-0.103890    -0.038772    -0.160811    0.055715    -0.127512  \n",
       "\n",
       "[119808 rows x 9 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_12k_10c = pd.DataFrame()   \n",
    "for index in range(10):\n",
    "    data = scipy.io.loadmat(file_paths[index])\n",
    "    dataList = data[data_columns[index]].reshape(-1)\n",
    "    data_12k_10c[columns_name[index]] = dataList[:119808] \n",
    "\n",
    "data_12k_10c.set_index('de_normal',inplace=True)\n",
    "\n",
    "if not os.path.exists(save_file_path):\n",
    "    os.makedirs(save_file_path)\n",
    "\n",
    "data_12k_10c.to_csv(save_file_path + '/' + 'data_12k_10c.csv')\n",
    "data_12k_10c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Train, Validation and Test Datasets, Including Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, time_steps, label, overlap_ratio=0.5):\n",
    "    \"\"\"\n",
    "        :Params\n",
    "        data: 1-D array or list\n",
    "        time_steps: int, the number of time steps in each sample\n",
    "        label: int, the label of the sample\n",
    "        overlap_ratio: float, the overlap ratio of the samples\n",
    "    \"\"\"\n",
    "    \n",
    "    stride = int(time_steps * (1 - overlap_ratio))  \n",
    "    samples = (len(data) - time_steps) // stride + 1  \n",
    "    clasiffy_dataFrame = pd.DataFrame(columns=[x for x in range(time_steps + 1)])  \n",
    "    data_list = []\n",
    "    for i in range(samples):\n",
    "        start_idx = i * stride\n",
    "        end_idx = start_idx + time_steps\n",
    "        temp_data = data[start_idx:end_idx].tolist()\n",
    "        temp_data.append(label) \n",
    "        data_list.append(temp_data)\n",
    "    clasiffy_dataFrame = pd.DataFrame(data_list, columns=clasiffy_dataFrame.columns)\n",
    "    return clasiffy_dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "        :params\n",
    "            x: input data\n",
    "    \"\"\"\n",
    "    y = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datasets(data_file,\n",
    "                      split_ratio=[0.7, 0.2, 0.1],\n",
    "                      step=512,\n",
    "                      ratio=0.5):\n",
    "    \"\"\"\n",
    "        :param\n",
    "        data_file: csv file\n",
    "        split_ratio: train, val, test\n",
    "        step: time step\n",
    "        ratio: overlap ratio\n",
    "        \n",
    "        :return\n",
    "        train_data\n",
    "        val_data\n",
    "        test_data\n",
    "    \"\"\"\n",
    "    origin_data = pd.read_csv(data_file)\n",
    "\n",
    "    dataframes = []\n",
    "    label = 0\n",
    "    \n",
    "    for col_name, col_data in origin_data.items():\n",
    "        # 1. Normalization (optional)\n",
    "        # col_data = normalize(col_data)\n",
    "        splited_data = split_data(col_data,\n",
    "                                  step,\n",
    "                                  label,\n",
    "                                  ratio)\n",
    "        \n",
    "        label += 1\n",
    "        dataframes.append(splited_data)\n",
    "        \n",
    "    all_data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # randomize the sequence of the data\n",
    "    all_data = all_data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # split the data\n",
    "    train_data = all_data.iloc[:int(len(all_data) * split_ratio[0])]\n",
    "    val_data = all_data.iloc[int(len(all_data) * split_ratio[0]):int(len(all_data) * (split_ratio[0] + split_ratio[1]))]\n",
    "    test_data = all_data.iloc[int(len(all_data) * (split_ratio[0] + split_ratio[1])):]\n",
    "    \n",
    "    return train_data, val_data, test_data, all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['files/test_set']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_rate = [0.7, 0.2, 0.1]\n",
    "raw_data_file_csv = 'files/data_12k_10c.csv'\n",
    "\n",
    "train_set, val_set, test_set, all_data = generate_datasets(raw_data_file_csv, \n",
    "                                                               split_rate)\n",
    "\n",
    "dump(train_set, save_file_path + '/' + 'train_set') \n",
    "dump(val_set, save_file_path + '/' + 'val_set') \n",
    "dump(test_set, save_file_path + '/' + 'test_set') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4670, 513)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['files/testY_512_10c']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "\n",
    "# 制作数据集和标签\n",
    "def make_data_labels(dataframe):\n",
    "    '''\n",
    "        参数 dataframe: 数据框\n",
    "        返回 x_data: 数据集     numpy.ndarray\n",
    "            y_label: 对应标签值  numpy.ndarray\n",
    "    '''\n",
    "    # 信号值\n",
    "    x_data = dataframe.iloc[:, 0:-1].values\n",
    "    # 标签值\n",
    "    y_label = dataframe.iloc[:, -1].values\n",
    "    x_data = x_data.astype(np.float32)\n",
    "    y_label = y_label.astype(np.int64)  # 指定了这些张量的数据类型为64位整数，通常用于分类任务的类别标签\n",
    "    return x_data, y_label\n",
    "\n",
    "# Load datas and generate labels\n",
    "train_set = load(save_file_path + '/train_set') \n",
    "val_set = load(save_file_path + '/val_set') \n",
    "test_set = load(save_file_path + '/test_set') \n",
    "\n",
    "# 制作标签\n",
    "train_xdata, train_ylabel = make_data_labels(train_set)\n",
    "val_xdata, val_ylabel = make_data_labels(val_set)\n",
    "test_xdata, test_ylabel = make_data_labels(test_set)\n",
    "\n",
    "# 保存数据\n",
    "dump(train_xdata, save_file_path + '/trainX_512_10c')\n",
    "dump(val_xdata, save_file_path + '/valX_512_10c')\n",
    "dump(test_xdata, save_file_path + '/testX_512_10c')\n",
    "dump(train_ylabel, save_file_path + '/trainY_512_10c')\n",
    "dump(val_ylabel, save_file_path + '/valY_512_10c')\n",
    "dump(test_ylabel, save_file_path + '/testY_512_10c')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3269, 512)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compatibility check is complete!\n"
     ]
    }
   ],
   "source": [
    "assert train_xdata.shape[0] == train_ylabel.shape[0]\n",
    "assert val_xdata.shape[0] == val_ylabel.shape[0]\n",
    "assert test_xdata.shape[0] == test_ylabel.shape[0]\n",
    "\n",
    "print('Compatibility check is complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
